{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/2022-1/notebooks/1e_pytorch_apis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs en PyTorch\n",
    "\n",
    "Curso: [Aprendizaje Profundo](http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_profundo/). Profesor: [Gibran Fuentes Pineda](http://turing.iimas.unam.mx/~gibranfp/). Ayudantes: [Bere](https://turing.iimas.unam.mx/~bereml/) y [Ricardo](https://turing.iimas.unam.mx/~ricardoml/).\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "En esta libreta veremos de manera breve las interfaces de programación de aplicaciones ([API](https://es.wikipedia.org/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones)s) para la definición de arquitecturas que provee PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preparación\n",
    "\n",
    "### 1.1 Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# sistema de archivos\n",
    "import os\n",
    "# números aleatorios\n",
    "import random\n",
    "\n",
    "# gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "# arreglos multidimensionales\n",
    "import numpy as np\n",
    "# csv\n",
    "import pandas as pd\n",
    "\n",
    "# redes neuronales\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos\n",
    "URL = 'https://raw.githubusercontent.com/gibranfp/CursoAprendizajeProfundo/2022-1/data/califs.csv'\n",
    "data_dir = '../data'\n",
    "filepath = os.path.join(data_dir, 'califs.csv')\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    \"\"\"Initializes pseudo-random number generators.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../data’: File exists\n",
      "File ‘../data/califs.csv’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "! mkdir {data_dir}\n",
    "! wget -nc {URL} -O {filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev</th>\n",
       "      <th>horas</th>\n",
       "      <th>calif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prev  horas  calif\n",
       "0   5.6    8.2    5.1\n",
       "1   6.7    9.3    5.9\n",
       "2   5.1   10.0    5.4\n",
       "3   5.7   10.4    6.5\n",
       "4   7.1   10.4    6.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos los datos para tener una idea más clara de como se encuentran distribuidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW60lEQVR4nO3de5AlZXnH8d8PVtiZFWGFAaOwLqBZYFkEHBRRQEVFUUBFlAQNiIpUjIAGoxZJ0KCWiJpSSaxaJXIR8QKSgBdASS2CBsZZWJblFsrlIogwCghxJwLZJ390z3Jm9pyZnjOnT9++n6qpc+3Tz3tYnul5336edkQIAFA/mxQdAAAgHyR4AKgpEjwA1BQJHgBqigQPADU1r+gAWm2zzTaxePHiosMAgMpYuXLl7yJiqN1rpUrwixcv1ujoaNFhAEBl2L6n02tM0QBATZHgAaCmSPAAUFMkeACoKRI8ANQUCR4AaooED6D0xteOa2TpiFbMW6GRpSMaXztedEiVQIIHUHo3H3qz1t2+Tvo/ad3t63TzoTcXHVIlkOABlN66O9ZJ69MH69PHmBEJHkDpDS4ZfDpbbZI+xoxI8ABKb9llyzS4y6C0qTS4y6CWXbas6JAqoVS9aACgnYGdBvSSW17S9/2Orx1P5v/vWKfBJckvloGdBvoeR7c4ggeADqq+uEuCB4AOqr64S4IHgA6qvriba4K3fZLtNbZvsX1ynvsCgF6r+uJuboustneX9D5JL5H0hKTLbf8wIu7Ma58A0EtFLe72Sp5H8LtKui4i1kXEU5KulvSWHPcHAGiRZ4JfI+kA21vbHpR0iKQdpr7J9vG2R22Pjo2N5RgOADRLbgk+Im6TdIakn0i6XNJNkp5q877lETEcEcNDQ22vGwsA6EKui6wRcXZE7B0RB0h6WBLz7wDQJ3mfRbNtertI0lslXZjn/gA0By2EZ5b3efAX275V0mWSPhARj+S8PwANUfUq037ItRdNROyf5+cDaK6qV5n2A5WsACqp6lWm/UCCB1BJVa8y7QfaBQOopKpXmfYDR/AAUFMkeACoKRI8ANQUCR4AaooEDwA1RYIHgJoiwQNATZHgAaCmSPAAaqNqHSbzjpcED6A2qtZhMu94SfAAaqNqHSbzjpcED6A2qtZhMu94SfAAaqNqHSbzjpdukgBqI2uHyfG148n89x3rNLgkSawDOw30IcLJ8u6IyRE8gMap2mJst0jwABqnaoux3SLBA2icqi3GdosED6BxqrYY2y0SPADUFAkeQOOwyAoANcUiKwDUFIusAFBTTVlkpZIVQONUreK1WxzBA0AHVV+MJcEDQAdVX4wlwQNAB1VfjCXBA0AHVV+MZZEVADrIu51v3jiCB4CaIsEDQE2R4AGgpkjwAAozvnZcI0tHtGLeCo0sHdH42vE5va8fsVQJCR5AYbIWEvWj4KjqRU3tkOABFCZrIVE/Co6qXtTUDgkeQGGyFhL1o+Co6kVN7eSa4G1/yPYtttfYvtD2/Dz3B6BashYS9aPgqOpFTe04IvL5YPt5kq6VtFtEjNv+rqQfRcQ5nbYZHh6O0dHRXOIBgDqyvTIihtu9lvcUzTxJA7bnSRqU9Juc9wcASOWW4CPifkmfl3SvpAck/SEirpz6PtvH2x61PTo2NpZXOADQOLkleNsLJR0uaUdJz5W0wPY7p74vIpZHxHBEDA8NDeUVDgA0Tp5TNK+RdFdEjEXEk5K+L2m/HPcHAGiRZ4K/V9K+tgdtW9JBkm7LcX9AYepYBdlrfEf9l+cc/PWSLpJ0g6Sb030tz2t/QJHqWAXZa3xH/ZdrP/iIOE3SaXnuAyiDOlZB9hrfUf9RyQr0QB2rIHuN76j/SPBAD9SxCrLX+I76j0v2AT0wl0u7ja8dT+an71inwSVJ4hvYaaCr7SR19Vl5aBdflS9/V0W5tSroBq0K0EQjS0eSxcf1SqYudhnMlAjbbSepq8/KQ7fjwuxM16qAI3igYN0uPnbcriQLmSyqFo85eKBg3S4+ttuuTAuZZYqlqUjwQMG6XXxst12ZFjLLFEtTMUUDFKzbBdpO2xUxz91pwRfFIsEDmLMNVarrJ1epTn2ORdb+IsEDmLOyL/g2VeYEb3s/SYtbt4mI83KICUDFDC4ZnHxK5JI2p2yyyNp3mRZZbZ+v5OIdr5C0T/rT9rxLAL1X9k6MZV/wbapMhU62b1NybdVcq6IodALao2gInfTimqxrJD2ndyEBmA2KhtCNrHPw20i61faIpD9NPBkRh+USFYBJOs1xA9PJmuA/kWcQAKa37LJlnGeOWcuU4CPiatvbKVlclaSRiHgov7AAtJpLt8p+6LYjJvLVcQ7e9qKW+2+XNCLpSElvl3S97bflHx6AKuByfOU03RH8vraPjIgvSDpV0j4TR+22hyT9VMk1VwE0HIvA5dTxCD4ivivptxPvmzIl8/vptgXQLHSOLKdpk3REXJDevdz2FbaPtX2spB9K+lHewQGoBoqayinrIutHbB8h6eWSLGl5RFySa2RAQz2y4hGtPni14omQN7P2uGIPLXzlwqLDmlbZF4GbKnMvmoi4WNLFOcYCQNqQ3CUpngitPni1DvzTgQVHhSqaNsHbvjYiXmH7cUmtbQosKSLiWblGBzTQRHLv9BjIatoEHxGvSG+36E84ALyZJyV1b+YCo0GVZe0mua/tLVoeP9P2S/MLC2iuPa7YY0NSn5iDB7qR9VTHr0r6n5bH69LnAPTY/EXzNfCCAWlTaeAFA5q/aH7RIc2o7O2Mmyprgndrq+CIWC+uBgXkoopVoVWMuQmyJvi1tk+0/Yz05yRJa/MMDGiqKlaFVjHmJsia4E+QtJ+k+yXdJ+mlko7PKyigyapYFVrFmJsgU4KPiIci4qiI2DYitouIv6SbJJCPKlaFVjHmJsg0j257vqT3SFoqacOKT0Qcl1NcwEaytKStQ9taqkLRK1mnaM5Xcsm+gyVdLWl7SY/nFRTQTpaFPBb7isH3Xk5ZE/wLIuIfJP0xIs6V9EZJ/A2GvsqykMdiXzH43sspa4J/Mr191PbukraUtDiXiIAOsizksdhXDL73csqa4JfbXijp7yVdKulWSZ/LLSqgjSwLeSz2FYPvvZzcUr9UuOHh4RgdHS06DACoDNsrI2K43WtZe9F8xvZWLY8X2v5Uj+IDAOQg6xTNGyLi0YkHEfGIpENyiQgA0BNZE/ymtjefeGB7QNLm07xftpfYXtXy85jtk+cQKwBgFrI2DPumpKtsf0PJhT+Ok3TudBtExB2S9pQk25sqaXPAZf5QKVkLp+pQYDUXTR9/WWVtVfA5SZ+WtKuSatbT0+eyOkjSryLintmHCBQnawFP0wt9mj7+sprNNVl/LOnHXe7nKEkXtnvB9vFKG5ctWrSoy48H8pG1gKfphT5NH39ZTXsEb/va9PbxdA594udx249l2YHtzSQdJul77V6PiOURMRwRw0NDQ7ONH8hV1gKephf6NH38ZTXTFM1fSck1WSPiWS0/W8zigttvkHRDRDw4p0iBAmQt4Gl6oU/Tx19W0xY6pSfQv9j2VRFxUFc7sL8t6YqI+MZM76XQCU3U7QIlC5uQpi90mmkOfhPbp0n6c9sfnvpiRHxxhh0PSnqtpPdnDRZomg0LlOufXqDM0i642+3QHDMl+KMkvTl93xaz/fCIWCdp69mHBTRHtwuULGxiJtMm+PRc9jNsr07PogHQY4NLBjccic9mgbLb7dAc0yZ42++MiG9K2s32rlNfn2mKBsDMll22bKO59Dy3Q3PMNEWzIL19Zt6BoBnqujA4l3F1e4k+Lu2HmdAuGH01snRk8rTCLoO1SFJ1HRfKr+uzaGx/ebrXI+LEuQSG5qnrwmBdx4Vqm2mKZmVfokBj1HVhsK7jQrXNdBbNtB0jgdmq68JgXceFasvUbMz2kKSPStpN0vyJ5yPi1TnFBXRlLouddV0Azqrp46+jrBf8uEDSbZJ2lPRJSXdL+mVOMaHG8m4rO5fPL2rbsqjDGDBZ1gS/dUScLenJiLg6Io6TtG+OcaGm8l6MnMvnF7VtWdRhDJgsa4J/Mr19wPYbbe8lafucYkKN5d1Wdi6fX9S2ZVGHMWCyrAn+U7a3lPS3kk6R9HVJJ+cVFOor77ayc/n8orYtizqMAZNlKnSyfa6kkyLi0fTxsyV9Pp2q6RkKnQAWOzE70xU6ZT2C32MiuUtSRDwsaa8exAZgChY70StZE/wmthdOPEiP4DNfzxVAdix2oleyJukvSPqF7YskhaS3S/p0blEBDUZVLHol0xF8RJwn6QhJD0oak/TWiDg/z8BQT+NrxzWydEQr5q3QyNIRja8dLzqk3HQ7VhY70St0k0RfNanrYpPGiuL0YpEV6IkmzS83aawoJxI8+qpJxTRNGivKiQSPvmrS/HKTxopy4lRH9FVdLzPXqTipjmNFdXAED/QAxUkoIxI80AMsqKKMSPBAD7CgijIiwQM9wIIqyohFVqAHWFBFGXEEDwA1RYIHgJoiwQNATZHgAaCmSPAoXJNaCAP9RIJH4agCBfJBgkfhqAIF8kGCR+GoAgXyQYJH4agCBfJBJSsKRxUokA+O4AGgpkjwAFBTuSZ421vZvsj27bZvs/2yPPcHAHha3nPwX5J0eUS8zfZmkjg9AgD6JLcjeNvPknSApLMlKSKeiIhH89ofqoGqVaB/8pyi2UnSmKRv2L7R9tdtL8hxf6gAqlaB/skzwc+TtLekr0bEXpL+KOljU99k+3jbo7ZHx8bGcgwHZUDVKtA/eSb4+yTdFxHXp48vUpLwJ4mI5RExHBHDQ0NDOYaDMqBqFeif3BJ8RPxW0q9tL0mfOkjSrXntr27qOldN1SrQP3mfRfNBSRekZ9CslfTunPdXGxvmqtc/PVddh2pPqlaB/sk1wUfEKknDee6jrpirBjBXVLKWFHPVAOaKBF9SzFUDmCu6SZYUc9UA5oojeACoKRI8ANQUCR4AaooEDwA1RYIH+qiuFcooJxI80Ed000Q/keCBPqJCGf1Eggf6iApl9BMJHugjKpTRT1SyAn1EhTL6iSN4AKgpEjwA1BQJHgBqigQPADVFggeAmiLBA0BNkeABoKZI8ABQUyR4TIvuh0B1keAxLbofAtVFgse06H4IVBcJHtOi+yFQXSR4TIvuh0B10U0S06L7IVBdHMEDQE2R4AGgpkjwAFBTJHgAqCkSPADUFAkeAGqKBA8ANUWCB4CaIsEDQE1VPsHTzhYA2qt8gqedLQC0V/kETztbAGiv8gmedrYA0F6uCd723bZvtr3K9mge+6CdLQC01492wa+KiN/l9eG0swWA9io/RQMAaC/vBB+SrrS90vbx7d5g+3jbo7ZHx8bGcg4HAJoj7wT/8ojYW9IbJH3A9gFT3xARyyNiOCKGh4aGcg4HAJoj1wQfEb9Jbx+SdIkkJssBoE9yS/C2F9jeYuK+pNdJWpPX/gAAk+V5Fs12ki6xPbGfb0XE5TnuDwDQwhFRdAwb2B6TdM+Up7eRlNtpln3CGMqBMZRDHcYglWccz4+ItguYpUrw7dgejYjhouOYC8ZQDoyhHOowBqka4+A8eACoKRI8ANRUFRL88qID6AHGUA6MoRzqMAapAuMo/Rw8AKA7VTiCBwB0gQQPADVV2gRv+0O2b7G9xvaFtucXHVM3bJ+UjuEW2ycXHU8Wtv/N9kO217Q892zbP7F9Z3q7sMgYZ9JhDEem/x3W2y716W1SxzGcaft226ttX2J7qwJDnFGHMZyexr/K9pW2n1tkjDNpN4aW106xHba3KSK2mZQywdt+nqQTJQ1HxO6SNpV0VLFRzZ7t3SW9T0kPnhdJepPtFxYbVSbnSHr9lOc+JumqiHihpKvSx2V2jjYewxpJb5X0s75H051ztPEYfiJp94jYQ9J/S/p4v4OapXO08RjOjIg9ImJPST+Q9I/9DmqWztHGY5DtHSS9VtK9/Q4oq1Im+NQ8SQO250kalPSbguPpxq6SrouIdRHxlKSrJb2l4JhmFBE/k/TwlKcPl3Ruev9cSW/uZ0yz1W4MEXFbRNxRUEiz1mEMV6b/liTpOknb9z2wWegwhsdaHi5Q0la8tDr8/yBJ/yzp71Ti+EuZ4CPifkmfV/Kb8QFJf4iIK4uNqitrJB1ge2vbg5IOkbRDwTF1a7uIeECS0tttC44H0nGSflx0EN2w/Wnbv5Z0tMp/BL8R24dJuj8ibio6lumUMsGn87uHS9pR0nMlLbD9zmKjmr2IuE3SGUr+rL5c0k2Snpp2IyAD26cq+bd0QdGxdCMiTo2IHZTE/zdFxzMb6cHaqarAL6ZSJnhJr5F0V0SMRcSTkr4vab+CY+pKRJwdEXtHxAFK/sy7s+iYuvSg7T+TpPT2oYLjaSzbx0h6k6Sjo/qFLN+SdETRQczSzkoOPm+yfbeSabIbbD+n0KjaKGuCv1fSvrYHnfQbPkjSbQXH1BXb26a3i5Qs8F1YbERdu1TSMen9YyT9R4GxNJbt10v6qKTDImJd0fF0Y8qJBodJur2oWLoRETdHxLYRsTgiFku6T9LeEfHbgkPbSGkrWW1/UtI7lPwZeqOk90bEn4qNavZsXyNpa0lPSvpwRFxVcEgzsn2hpFcqaYf6oKTTJP27pO9KWqTkF/CREdFu4akUOozhYUlfkTQk6VFJqyLi4IJCnFGHMXxc0uaSfp++7bqIOKGQADPoMIZDJC2RtF5Je/AT0nW3Umo3hog4u+X1u5Wc8VeG1sGTlDbBAwDmpqxTNACAOSLBA0BNkeABoKZI8ABQUyR4AKgpEjwKZXtxuy59RbD9Cdun5PTZW9n+6y62e6XtH6T3D7Nd9iZvKBESPCotbUZXBVtJmnWCbxURl0bEZ3sTDpqABI8y2NT219Je7VfaHpAk23vavq6l9/nC9PkVtj9j+2pJJ9k+1Pb1tm+0/VPb26XvOzDtOb4qfW2LqTu2fartO2z/VEnxzcTzO9u+3PZK29fY3qXNtgvSXuG/TD//8PT5pbZH0v2uTis3Pytp5/S5M1uPzNNtzrJ9bHr/9WnP92uVVD9PvOdY22el959v+6r0869KK6WBSUjwKIMXSvqXiFiqpMJ0ojfJeZI+mvY+v1lJFeSErSLiwIj4gqRrJe0bEXtJ+raSFq6SdIqkD6R9x/eXNN66U9svVnKdgb2UJNJ9Wl5eLumDEfHi9HP+tU3cp0r6z4jYR9KrJJ1pe4GkEyR9Kd3vsJJS9o9J+lVE7BkRH+n0RTi5sM3XJB2axtypv8lZks5Lv5sLJH2502eiuary5y3q7a6IWJXeXylpse0tlSTxq9Pnz5X0vZZtvtNyf3tJ30mboG0m6a70+Z9L+qLtCyR9PyLum7Lf/SVdMtHTxfal6e0zlTS3+17SCklS0h5gqtdJOqxl3n6+klYO/yXpVNvbp/u9s+VzZrKLku/jzjSWb0o6vs37Xqanj+7Pl/S5rDtAc3AEjzJo7TH0f8p24PHHlvtfkXRWRCyT9H4liVbpfPV7JQ1Iuq7dNIvaX6xhE0mPpkfbEz+7tnmfJR3R8p5F6UVFvqWkida4pCtsv7rNtk9p8v9/rZek7KZ/CD1HsBESPEopIv4g6RHb+6dPvUvJFbHa2VLSRLOqiY6Xsr1z2vnvDEmjSo6OW/1M0ltsD6Tz84em+35M0l22j0w/x7Zf1Ga/V0j6YNrxVLb3Sm93krQ2Ir6spAvnHpIel9S6BnCPpN1sb57+tXJQ+vztkna0vXP6+C86jPkXevoylkcrmaYCJiHBo8yOUTKvvVrSnpL+qcP7PqFkOuUaSa0d/U52csHzm5QcTU+6+lFE3KBkqmeVpIslXdPy8tGS3pNue4uSC9BMdbqkZ0hanZ7qeXr6/DskrbG9SskvlfMi4veSfp7Gc2ZE/FpJd87VSubQb0xj+l8lUzI/TBdZ7+kw5hMlvTv9bt4l6aQO70OD0U0SAGqKI3gAqCkSPADUFAkeAGqKBA8ANUWCB4CaIsEDQE2R4AGgpv4fRMvzHSbh7DUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se obtiene el atributo de entrada y se agrega una dimensión\n",
    "x_trn = np.array(df.iloc[:,1], dtype='float32')[..., np.newaxis]\n",
    "# se obtiene la salda\n",
    "y_trn = np.array(df.iloc[:,-1], dtype='float32')[..., np.newaxis]\n",
    "# graficamos\n",
    "plt.plot(x_trn, y_trn, '.', color='m', markersize=8)\n",
    "plt.xlabel('horas de estudio')\n",
    "plt.ylabel('calificación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n",
      "torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "x_trn = np.array(df.iloc[:,:2], dtype=\"float32\")\n",
    "y_trn = np.array(df.iloc[:,-1], dtype=\"float32\")[..., np.newaxis]\n",
    "\n",
    "x_trn = torch.tensor(x_trn)\n",
    "y_trn = torch.tensor(y_trn)\n",
    "\n",
    "print(x_trn.shape)\n",
    "print(y_trn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Conjunto de datos\n",
    "\n",
    "Para hacer lotes podemos user las clase [`TensorDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/bereml/iap/master/fig/mnist_pipeline.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.6000, 8.2000]), tensor([5.1000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TensorDataset(x_trn, y_trn)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cargador de datos\n",
    "\n",
    "\n",
    "Para ver el funcionamiento de la tubería de datos imprimimos la forma de cada lote y su primer elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape=torch.Size([16, 2]) dtype=torch.float32\n",
      "y shape=torch.Size([16, 1]) dtype=torch.float32\n"
     ]
    }
   ],
   "source": [
    "def build_dl(batch_size=16, shuffle=True):\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# creamos un DataLoader\n",
    "dl = build_dl()\n",
    "\n",
    "x, y = next(iter(dl))\n",
    "print(f'x shape={x.shape} dtype={x.dtype}')\n",
    "print(f'y shape={y.shape} dtype={y.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Ciclo de entrenamiento\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/bereml/iap/master/fig/supervisado.svg\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizador\n",
    "def train(model, dl, epochs=5):\n",
    "\n",
    "    opt = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # historial de pérdida\n",
    "    loss_hist = []\n",
    "\n",
    "    # ciclo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # historial\n",
    "        loss_hist = []\n",
    "        \n",
    "        # entrenamiento de una época\n",
    "        for x, y_true in dl:\n",
    "            # hacemos inferencia para obtener los logits\n",
    "            y_lgts = model(x)\n",
    "            # calculamos de pérdida\n",
    "            loss = F.mse_loss(y_lgts, y_true)\n",
    "            # vaciamos los gradientes\n",
    "            opt.zero_grad()\n",
    "            # retropropagamos\n",
    "            loss.backward()\n",
    "            # actulizamos parámetros\n",
    "            opt.step()\n",
    "\n",
    "            # guardamos historial de pérdida\n",
    "            loss_hist.append(loss.item() * 100)\n",
    "            \n",
    "        # imprimimos la pérdida de la época\n",
    "        loss = np.mean(loss_hist)\n",
    "        print(f'E{epoch:02} loss=[{loss:6.2f}]')\n",
    "\n",
    "        \n",
    "def train_model(build_model, epochs=5):\n",
    "    set_seed()\n",
    "    dl = build_dl()\n",
    "    model = build_model()\n",
    "    train(model, dl, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Definición de la arquitectura\n",
    "\n",
    "Para implementar arquitecturas, PyTorch define dos clases fundamentales.\n",
    "\n",
    "* `nn.Module` define una red neuronal que internamente puede tener otras redes neuronales anidadas (o capas). Tres metodos importantes son:\n",
    "  * `__init__(self, args)` es el inicilizador que define al objeto,\n",
    "  * `fordward(x)` realizar predicción (hacia adelante),\n",
    "  * `parameters(x)` regresa una lista de los parámetros (`nn.Parameter`) de la red y redes anidadas.\n",
    "\n",
    "\n",
    "* `nn.Parameter` envuelve un tensor solo para marcarlo como parámetro y que sea regresado por `nn.Module.parameters(x)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Alto nivel (similar a Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta API basta con apilar las capas (del paquete [`torch.nn`](https://pytorch.org/docs/stable/nn.html)) usando la clase [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_high():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2, 1),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_high()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Medio nivel (Chainer, tensorflow.keras.model)\n",
    "\n",
    "En esta API heredamos de [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module), creamos las capas en el inicializador e implementamos la inferencia en el método `fordward`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinRegMed(\n",
       "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#se define la clase RegLin que hereda de torch.nn.Module\n",
    "class LinRegMed(nn.Module):\n",
    "\n",
    "    #se define el inicializador\n",
    "    def __init__(self):\n",
    "        # se llama al inicializador de la clase padre\n",
    "        super().__init__()\n",
    "        # importante: se definen las capas como atributos de la clase\n",
    "        self.fc1 = nn.Linear(2, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    # método para inferencia\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def build_med():\n",
    "    return LinRegMed()\n",
    "\n",
    "build_med()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Bajo nivel\n",
    "\n",
    "En esta interfaz debemos implementar las capaz partiendo de los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, init):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.init = init\n",
    "        # se envuelven los tensores en parámetros (clase)\n",
    "        # para que model.parameters() los regrese\n",
    "        # y sean visibles al optimizador\n",
    "        self.weight = nn.Parameter(torch.zeros(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        if init == 'he':\n",
    "            self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Delving Deep into Rectifiers: \n",
    "        #   Surpassing Human-Level Performance on ImageNet Classification\n",
    "        # https://arxiv.org/abs/1502.01852\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # X * W + B\n",
    "        return F.linear(x, self.weight, self.bias)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, init={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.init, self.bias is not None\n",
    "        )\n",
    "\n",
    "\n",
    "class LinRegLow(nn.Module):\n",
    "\n",
    "    def __init__(self, init='zeros'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cls = nn.Sequential(\n",
    "            MyLinear(2, 2, init),\n",
    "            nn.ReLU(),\n",
    "            MyLinear(2, 1, init),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cls(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinRegLow(\n",
       "  (cls): Sequential(\n",
       "    (0): MyLinear(in_features=2, out_features=2, init=he, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): MyLinear(in_features=2, out_features=1, init=he, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_low_he():\n",
    "    return LinRegLow(init='he')\n",
    "\n",
    "build_low_he()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinRegLow(\n",
       "  (cls): Sequential(\n",
       "    (0): MyLinear(in_features=2, out_features=2, init=zeros, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): MyLinear(in_features=2, out_features=1, init=zeros, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_low_zeros():\n",
    "    return LinRegLow(init='zeros')\n",
    "\n",
    "build_low_zeros()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Entrenando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 loss=[5240.13]\n",
      "E01 loss=[2730.91]\n",
      "E02 loss=[622.67]\n",
      "E03 loss=[ 47.03]\n",
      "E04 loss=[ 16.73]\n"
     ]
    }
   ],
   "source": [
    "train_model(build_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 loss=[5240.13]\n",
      "E01 loss=[2730.91]\n",
      "E02 loss=[622.67]\n",
      "E03 loss=[ 47.03]\n",
      "E04 loss=[ 16.73]\n"
     ]
    }
   ],
   "source": [
    "train_model(build_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 loss=[5240.13]\n",
      "E01 loss=[2730.91]\n",
      "E02 loss=[622.67]\n",
      "E03 loss=[ 47.03]\n",
      "E04 loss=[ 16.73]\n"
     ]
    }
   ],
   "source": [
    "train_model(build_low_he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 loss=[5586.75]\n",
      "E01 loss=[5281.79]\n",
      "E02 loss=[5079.85]\n",
      "E03 loss=[4928.56]\n",
      "E04 loss=[4967.41]\n",
      "E05 loss=[5092.14]\n",
      "E06 loss=[4979.04]\n",
      "E07 loss=[4874.94]\n",
      "E08 loss=[4741.26]\n",
      "E09 loss=[4634.36]\n",
      "E10 loss=[4300.48]\n",
      "E11 loss=[4150.66]\n",
      "E12 loss=[4242.56]\n",
      "E13 loss=[4827.45]\n",
      "E14 loss=[4070.02]\n",
      "E15 loss=[4345.31]\n",
      "E16 loss=[4081.96]\n",
      "E17 loss=[4353.34]\n",
      "E18 loss=[3907.37]\n",
      "E19 loss=[4045.78]\n",
      "E20 loss=[3561.13]\n",
      "E21 loss=[3714.62]\n",
      "E22 loss=[3872.94]\n",
      "E23 loss=[3616.32]\n",
      "E24 loss=[3596.34]\n",
      "E25 loss=[3809.44]\n",
      "E26 loss=[3482.73]\n",
      "E27 loss=[3434.74]\n",
      "E28 loss=[3262.29]\n",
      "E29 loss=[3426.96]\n",
      "E30 loss=[3523.23]\n",
      "E31 loss=[3233.74]\n",
      "E32 loss=[3154.37]\n",
      "E33 loss=[2906.46]\n",
      "E34 loss=[3174.32]\n",
      "E35 loss=[3401.14]\n",
      "E36 loss=[3237.41]\n",
      "E37 loss=[2964.21]\n",
      "E38 loss=[2828.31]\n",
      "E39 loss=[3274.97]\n",
      "E40 loss=[2859.65]\n",
      "E41 loss=[2756.75]\n",
      "E42 loss=[2838.57]\n",
      "E43 loss=[2767.52]\n",
      "E44 loss=[2539.08]\n",
      "E45 loss=[2510.41]\n",
      "E46 loss=[2434.60]\n",
      "E47 loss=[2533.85]\n",
      "E48 loss=[2765.56]\n",
      "E49 loss=[2469.54]\n"
     ]
    }
   ],
   "source": [
    "train_model(build_low_zeros, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Obteniendo  parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = build_high()\n",
    "med = build_med()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0297,  0.4558],\n",
       "         [-0.5345, -0.4854]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4106,  0.4949], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2542,  0.5964]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2557], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(high.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0895, -0.0053],\n",
       "         [-0.1398,  0.0887]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1615, -0.0050], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0902, -0.5531]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3706], requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(med.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0297,  0.4558],\n",
       "          [-0.5345, -0.4854]], requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.4106,  0.4949], requires_grad=True)),\n",
       " ('2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2542,  0.5964]], requires_grad=True)),\n",
       " ('2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.2557], requires_grad=True))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(high.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fc1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0895, -0.0053],\n",
       "          [-0.1398,  0.0887]], requires_grad=True)),\n",
       " ('fc1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1615, -0.0050], requires_grad=True)),\n",
       " ('fc2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0902, -0.5531]], requires_grad=True)),\n",
       " ('fc2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.3706], requires_grad=True))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(med.named_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
