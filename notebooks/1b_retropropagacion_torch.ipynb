{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/1b_retropropagacion_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V83__FrBij1f"
   },
   "source": [
    "# Retropropagación de errores\n",
    "\n",
    "En este *notebook* programaremos con PyTorch una red neuronal densa y la entrenaremos para aproximar la operación XOR usando del gradiente descedente con el algoritmo de retropropagación de errores. Recordemos que la operación XOR ($\\otimes$) está de la siguiente manera:\n",
    "\n",
    "| $x_1$ | $x_2$ | $y$\n",
    "| ------------- |:-------------:| -----:|\n",
    "|0 |0 |0|\n",
    "|0 |1 |1|\n",
    "|1 |0 |1|\n",
    "|1 |1 |0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSlnjW4Oi-FP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iAUmKI5jNuX"
   },
   "source": [
    "Nuestra red neuronal densa está compuesta por una capa de 2 entradas ($x_1$ y $x_2$), una capa oculta con 10 neuronas con función de activación sigmoide y una capa de salida con una sola neurona con función de activación sigmoide. Esta función de activación se define como:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYhT3i68jf6x"
   },
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1 / (1 + torch.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qx6SyrPhWBrw"
   },
   "source": [
    "La función sigmoide tiene una derivada que está expresada en términos de la misma función, esto es, \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJxvxKeAjn24"
   },
   "outputs": [],
   "source": [
    "def derivada_sigmoide(x):\n",
    "    s = sigmoide(x)\n",
    "    return s * (1.0 - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WxI8FfLXKHv"
   },
   "source": [
    "Podemos ver la operación XOR como una tarea de clasificación binaria a partir de 2 entradas. Por lo tanto, usaremos la función de pérdida de entropía cruzada binaria:\n",
    "\n",
    "$$\n",
    "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDjlmpAQjR3X"
   },
   "outputs": [],
   "source": [
    "def entropia_cruzada_binaria(y, p):\n",
    "    return -(torch.log(p[y == 1]).sum() + torch.log(1 - p[y == 0]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8nMdK-RYWMS"
   },
   "source": [
    "Asimismo, calcularemos la exactitud para medir el rendimiento del modelo aprendido por la red neuronal densa:\n",
    "\n",
    "$$\n",
    "exactitud = \\frac{correctos}{total}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wxvZq10jIM3"
   },
   "outputs": [],
   "source": [
    "def exactitud(y, y_predicha):\n",
    "    return (y == y_predicha).float().mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p02hAdUFZNLL"
   },
   "source": [
    "Ahora, definimos la función que propaga hacia adelante una entrada $\\mathbf{x}^{i}$. Como la red está compuesta de 2 capas densas (1 oculta y 1 de salida), tenemos 2 matrices de pesos con sus correspondientes vectores de sesgos $\\{\\mathbf{W}^{\\{1\\}}, \\mathbf{b}^{\\{1\\}}\\}$ y $\\{\\mathbf{W}^{\\{2\\}}, \\mathbf{b}^{\\{2\\}}\\}$ de la capa oculta y la capa de salida respectivamente. Así, podemos llevar a cabo la propagación hacia adelante en esta red de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\t\\begin{split}\n",
    "\t\t\t\t\\mathbf{a}^{\\{1\\}} & =  \\mathbf{x}^{(i)} \\\\\n",
    "\t\t\t\t\\mathbf{z}^{\\{2\\}} & =  \\mathbf{W}^{\\{1\\}} \\cdot \\mathbf{a}^{\\{1\\}} + \\mathbf{b}^{\\{1\\}}\\\\\n",
    "\t\t\t\t\\mathbf{a}^{\\{2\\}} & =  \\sigma(\\mathbf{z}^{\\{2\\}}) \\\\\n",
    "\t\t\t\t\\mathbf{z}^{\\{3\\}} & =  \\mathbf{W}^{\\{2\\}} \\cdot \\mathbf{a}^{\\{2\\}}  + \\mathbf{b}^{\\{2\\}}\\\\\n",
    "\t\t\t\t\\mathbf{a}^{\\{3\\}} & =  \\sigma(\\mathbf{z}^{\\{3\\}})\\\\\n",
    "\t\t\t\t\\hat{y}^{(i)} & =  \\mathbf{a}^{\\{3\\}}\n",
    "\t\t\t\\end{split}\n",
    "      $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAsEk-zajvpX"
   },
   "outputs": [],
   "source": [
    "def hacia_adelante(x, W1, b1, W2, b2):\n",
    "    z2 = W1.t() @ x + b1\n",
    "    a2 = sigmoide(z2)\n",
    "    z3 = W2.t() @ a2 + b2\n",
    "    y_hat = sigmoide(z3)\n",
    "  \n",
    "    return z2, a2, z3, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiOT6jqXjzwQ"
   },
   "source": [
    "Finalmente, definimos la función para entrenar nuestra red neuronal usando gradiente descendente. Para calcular el gradiente de la función de pérdida respecto a los pesos y sesgos en cada capa empleamos el algoritmo de retropropagación de errores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1P7i6eLgkJdg"
   },
   "outputs": [],
   "source": [
    "def retropropagacion(X, y, alpha = 0.01, n_epocas = 100, n_ocultas = 10):\n",
    "    n_ejemplos, n_entradas = X.shape\n",
    "    \n",
    "    # Inicialización de las matrices de pesos W y V\n",
    "    W1 = math.sqrt(1.0 / n_entradas) * torch.randn(n_entradas, n_ocultas)\n",
    "    b1 = torch.zeros(n_ocultas)\n",
    "    \n",
    "    W2 = math.sqrt(1.0 / n_ocultas) * torch.randn(n_ocultas)\n",
    "    b2 = torch.zeros(1)\n",
    "    \n",
    "    perdidas = torch.zeros(n_epocas)\n",
    "    exactitudes = torch.zeros(n_epocas)\n",
    "    y_predicha = torch.zeros(y.shape)\n",
    "    for i in range(n_epocas):\n",
    "        for j in range(n_ejemplos):\n",
    "            z2, a2, z3, y_hat = hacia_adelante(X[j], W1, b1, W2, b2)\n",
    "\n",
    "            # cálculo de gradiente para W2 por retropropagación\n",
    "            delta3 = (y_hat - y[j]) * derivada_sigmoide(z3)\n",
    "            W2 -= alpha * a2 * delta3\n",
    "            b2 -= alpha * delta3\n",
    "\n",
    "            # cálculo de gradiente para W1 por retropropagación\n",
    "            delta2 = W2 * delta3 * derivada_sigmoide(z2)\n",
    "            W1 -= alpha * torch.ger(X[j], delta2)\n",
    "            b1 -= alpha * delta2\n",
    "\n",
    "            y_predicha[j] = y_hat\n",
    "            \n",
    "        # calcula error en época\n",
    "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
    "        exactitudes[i] = exactitud(y, torch.round(y_predicha))\n",
    "        if (i+1) % 20 == 0:\n",
    "            print(f'Epoch {i+1}: Error = {perdidas[i]} Exactitud = {exactitudes[i]}')\n",
    "\n",
    "    return W1, W2, perdidas, exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nau0HWsrkRxg"
   },
   "source": [
    "Para probar nuestra red, generamos los ejemplos correspondientes a la operación XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8txXZ34GkUAF"
   },
   "outputs": [],
   "source": [
    "# ejemplo (XOR)\n",
    "X = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "y = torch.tensor([0., 1., 1., 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLT8avfhkYH7"
   },
   "source": [
    "Finalmente, entrenamos nuestra red con estos ejemplos por 200 épocas usando una tasa de aprendizaje $\\alpha = 1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ijKxVwZ3kbyR",
    "outputId": "7fc96d96-2f6a-4fef-a823-497e98220756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Error = 3.4514527320861816 Exactitud = 50.0\n",
      "Epoch 40: Error = 3.483663320541382 Exactitud = 50.0\n",
      "Epoch 60: Error = 3.5026187896728516 Exactitud = 50.0\n",
      "Epoch 80: Error = 3.4997472763061523 Exactitud = 50.0\n",
      "Epoch 100: Error = 3.4624674320220947 Exactitud = 50.0\n",
      "Epoch 120: Error = 3.372633934020996 Exactitud = 50.0\n",
      "Epoch 140: Error = 3.2141807079315186 Exactitud = 50.0\n",
      "Epoch 160: Error = 2.993985891342163 Exactitud = 50.0\n",
      "Epoch 180: Error = 2.748088836669922 Exactitud = 75.0\n",
      "Epoch 200: Error = 2.48521089553833 Exactitud = 75.0\n",
      "Epoch 220: Error = 2.1526074409484863 Exactitud = 75.0\n",
      "Epoch 240: Error = 1.7091784477233887 Exactitud = 100.0\n",
      "Epoch 260: Error = 1.2717576026916504 Exactitud = 100.0\n",
      "Epoch 280: Error = 0.9692773222923279 Exactitud = 100.0\n",
      "Epoch 300: Error = 0.7800878286361694 Exactitud = 100.0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "W1, W2, perdidas, exactitudes = retropropagacion(X, \n",
    "                                                 y, \n",
    "                                                 alpha = 1.0, \n",
    "                                                 n_epocas = 300,\n",
    "                                                 n_ocultas = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8A3KZ5JkDJ3"
   },
   "source": [
    "Graficamos el valor de la pérdida y la exactitud en cada época para ver el comportamiento de nuestra red durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "yglJSF9nkR7k",
    "outputId": "059109ba-d686-42e1-b81d-1fa09bf01872"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax[0].plot(perdidas.numpy())\n",
    "ax[0].set_title('ECB')\n",
    "ax[1].plot(exactitudes.numpy())\n",
    "ax[1].set_title('Exactitud');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hz0OaZtsCCgs"
   },
   "source": [
    "## Inicializando los pesos con zeros\n",
    "Como se mencionó anteriormente, las matrices de pesos $\\mathbf{W^{\\{1\\}}}$ y $\\mathbf{W^{\\{2\\}}}$ se initializan con valores aleatorios pequeños mientras que los vectores de sesgo $\\mathbf{b^{\\{1\\}}}$ y $\\mathbf{b^{\\{1\\}}}$ con zeros. Examinemos qué pasa si inicializamos las matrices de pesos con zeros. Observa los valores de los pesos en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHaavbWGzqzg"
   },
   "outputs": [],
   "source": [
    "def retropropagacion_zeros(X, y, alpha = 0.1, n_epocas = 100, n_ocultas = 10):\n",
    "    n_ejemplos, n_entradas = X.shape\n",
    "    \n",
    "    # Inicializa matrices de pesos W1 y W2 y vectores de sesgos b1 y b2\n",
    "    W1 = torch.zeros(n_entradas, n_ocultas)\n",
    "    b1 = torch.zeros(n_ocultas) \n",
    "    W2 = torch.zeros(n_ocultas)\n",
    "    b2 = torch.zeros(1)\n",
    "    \n",
    "    perdidas = torch.zeros(n_epocas)\n",
    "    exactitudes = torch.zeros(n_epocas)\n",
    "    y_predicha = torch.zeros(y.shape)\n",
    "    for i in range(n_epocas):\n",
    "        for j in range(n_ejemplos):\n",
    "            z2, a2, z3, y_hat = hacia_adelante(X[j], W1, b1, W2, b2)\n",
    "\n",
    "            # cálculo de gradiente para W2 por retropropagación\n",
    "            delta3 = (y_hat - y[j]) * derivada_sigmoide(z3)\n",
    "            W2 -= alpha * a2 * delta3\n",
    "            b2 -= alpha * delta3\n",
    "\n",
    "            # cálculo de gradiente para W1 por retropropagación\n",
    "            delta2 = W2 * delta3 * derivada_sigmoide(z2)\n",
    "            W1 -= alpha * torch.ger(X[j], delta2)\n",
    "            b1 -= alpha * delta2\n",
    "\n",
    "            y_predicha[j] = y_hat\n",
    "            \n",
    "        # calcula error en época\n",
    "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
    "        exactitudes[i] = exactitud(y, torch.round(y_predicha))\n",
    "        print(f'Epoch {i+1}: Error = {perdidas[i]} Exactitud = {exactitudes[i]}')\n",
    "        print('W1 = {0}'.format(W1.numpy()))\n",
    "        print('W2 = {0}'.format(W2.numpy()))\n",
    "            \n",
    "    return W1, W2, perdidas, exactitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jr1HownICHf9",
    "outputId": "df1437c2-8cac-41af-f4a1-1e6a4bf4522e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Error = 3.257566452026367 Exactitud = 50.0\n",
      "W1 = [[0.00222783 0.00222783 0.00222783 0.00222783 0.00222783 0.00222783\n",
      "  0.00222783 0.00222783 0.00222783 0.00222783]\n",
      " [0.00047238 0.00047238 0.00047238 0.00047238 0.00047238 0.00047238\n",
      "  0.00047238 0.00047238 0.00047238 0.00047238]]\n",
      "W2 = [-0.00300507 -0.00300507 -0.00300507 -0.00300507 -0.00300507 -0.00300507\n",
      " -0.00300507 -0.00300507 -0.00300507 -0.00300507]\n",
      "Epoch 2: Error = 3.2594382762908936 Exactitud = 50.0\n",
      "W1 = [[0.00448687 0.00448687 0.00448687 0.00448687 0.00448687 0.00448687\n",
      "  0.00448687 0.00448687 0.00448687 0.00448687]\n",
      " [0.00092736 0.00092736 0.00092736 0.00092736 0.00092736 0.00092736\n",
      "  0.00092736 0.00092736 0.00092736 0.00092736]]\n",
      "W2 = [-0.00457636 -0.00457636 -0.00457636 -0.00457636 -0.00457636 -0.00457636\n",
      " -0.00457636 -0.00457636 -0.00457636 -0.00457636]\n",
      "Epoch 3: Error = 3.2615671157836914 Exactitud = 50.0\n",
      "W1 = [[0.00676583 0.00676583 0.00676583 0.00676583 0.00676583 0.00676583\n",
      "  0.00676583 0.00676583 0.00676583 0.00676583]\n",
      " [0.00137482 0.00137482 0.00137482 0.00137482 0.00137482 0.00137482\n",
      "  0.00137482 0.00137482 0.00137482 0.00137482]]\n",
      "W2 = [-0.00542247 -0.00542247 -0.00542247 -0.00542247 -0.00542247 -0.00542247\n",
      " -0.00542247 -0.00542247 -0.00542247 -0.00542247]\n",
      "Epoch 4: Error = 3.2637853622436523 Exactitud = 50.0\n",
      "W1 = [[0.00905938 0.00905938 0.00905938 0.00905938 0.00905938 0.00905938\n",
      "  0.00905938 0.00905938 0.00905938 0.00905938]\n",
      " [0.00182    0.00182    0.00182    0.00182    0.00182    0.00182\n",
      "  0.00182    0.00182    0.00182    0.00182   ]]\n",
      "W2 = [-0.00590347 -0.00590347 -0.00590347 -0.00590347 -0.00590347 -0.00590347\n",
      " -0.00590347 -0.00590347 -0.00590347 -0.00590347]\n",
      "Epoch 5: Error = 3.2660441398620605 Exactitud = 50.0\n",
      "W1 = [[0.01136488 0.01136488 0.01136488 0.01136488 0.01136488 0.01136488\n",
      "  0.01136488 0.01136488 0.01136488 0.01136488]\n",
      " [0.00226562 0.00226562 0.00226562 0.00226562 0.00226562 0.00226562\n",
      "  0.00226562 0.00226562 0.00226562 0.00226562]]\n",
      "W2 = [-0.00620192 -0.00620192 -0.00620192 -0.00620192 -0.00620192 -0.00620192\n",
      " -0.00620192 -0.00620192 -0.00620192 -0.00620192]\n"
     ]
    }
   ],
   "source": [
    "W1, W2, perdidas, exactitudes = retropropagacion_zeros(X, \n",
    "                                                       y, \n",
    "                                                       alpha = 1.0,\n",
    "                                                       n_epocas = 5,\n",
    "                                                       n_ocultas = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLY6IWl4J76S"
   },
   "source": [
    "## Tarea\n",
    "Modifica el código anterior para agregar una capa extra de neuronas ocultas.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1b_retropropagacion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
