{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/2024-1/notebooks/4a_gpt.ipynb)"
      ],
      "metadata": {
        "id": "jcvZoGIcARAc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zqNl1jobIA4"
      },
      "source": [
        "# Aplicaciones de Transformers (GPT)\n",
        "\n",
        "---\n",
        "Curso: Aprendizaje Profundo.\n",
        "\n",
        "Profesor: Gibran Fuentes Pineda.\n",
        "\n",
        "Ayudantes: Fernando Nava y Rodrigo del Moral\n",
        "\n",
        "---\n",
        "\n",
        "En esta libreta se explora una aplicación de los bloques Transformers. El código utiliza el bloque Transformer visto en clase y el modelo está basado en una implementación conocida como [nanoGPT](https://github.com/karpathy/nanoGPT/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0VTSiNcbIA6"
      },
      "source": [
        "## 1. Importar bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fjjvMifYZf7x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from torchsummary import summary\n",
        "\n",
        "th.manual_seed(22)\n",
        "device = 'cuda' if th.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmHEeS88bIA7"
      },
      "source": [
        "## 2. Conjunto de datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0cUTEbwHbIA7"
      },
      "outputs": [],
      "source": [
        "# descargar y abrir archivo (obras completas de Shakespeare en inglés)\n",
        "if not os.path.exists(\"input.txt\"):\n",
        "    ! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# generar el vocabulario del tokenizador (caracteres)\n",
        "voc = Counter([c for c in text])\n",
        "\n",
        "# crear diccionarios para mapear IDs y tokens\n",
        "i2p = {i:p for i,(p,f) in enumerate(voc.most_common())}\n",
        "p2i = {p:i for i,(p,f) in enumerate(voc.most_common())}\n",
        "# tamaño del vocabulario\n",
        "vocab_size = len(i2p)\n",
        "\n",
        "# crear funciones para convertir de IDs a tokens y viceversa\n",
        "encode = lambda s: [p2i[c] for c in s]\n",
        "decode = lambda l: ''.join([i2p[i] for i in l])\n",
        "\n",
        "# codificar el conjunto de datos entero y partirlo en train y valid\n",
        "data = th.tensor(encode(text), dtype=th.long)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(voc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EjoWuS1EaYP",
        "outputId": "041addf8-35a8-47b4-eb3e-d826697f469d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V7rVPAXbIA7"
      },
      "source": [
        "## 3. Cargador de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CWYpgPx2bIA8"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "context_size = 32\n",
        "\n",
        "# para generar los datos del modelo de lenguaje causal (predecir siguiente token)\n",
        "# las entradas son porciones de texto codificadas de tamaño context_size y\n",
        "# las salidas son las mismas porciones de texto recorridas un paso\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = th.randint(len(data) - context_size, (batch_size,))\n",
        "    x = th.stack([data[i:i+context_size] for i in ix])\n",
        "    y = th.stack([data[i+1:i+context_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_batch(\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ8ICDRFFG-W",
        "outputId": "3da46d86-795f-4fd6-eefe-0dcc0396985b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[14, 18,  3,  7,  2, 46, 10, 43, 15,  0,  4,  8, 12,  0, 22, 15, 25, 10,\n",
              "          21,  0,  5,  3, 23,  1,  0,  9,  2,  0,  9,  6,  0,  6],\n",
              "         [ 3, 13,  8,  2,  4,  9,  8, 16, 10, 49,  7,  3, 14,  0, 17,  5,  1,  8,\n",
              "           0,  2,  5,  9,  6,  0,  6,  2,  7,  1,  4, 14,  0,  2],\n",
              "         [ 5,  9,  6, 10, 27,  1,  7, 15,  0, 12,  4, 15,  0,  7,  1, 19,  1,  9,\n",
              "          27,  1,  6,  0, 11,  1,  2,  2,  1,  7,  6,  0,  3, 18],\n",
              "         [ 6,  0, 17,  1, 11, 11, 16,  0,  4,  8, 12,  0,  8,  3,  2,  5,  9,  8,\n",
              "          20,  0, 19,  4,  8,  0, 22,  1,  0,  9, 11, 11, 24, 10],\n",
              "         [ 3, 14, 23, 11,  3,  2,  2,  1, 12,  0,  4,  8, 12,  0, 19,  3,  8,  2,\n",
              "           7,  9, 27,  1, 12,  0,  9,  8,  0,  2,  5,  9,  6,  0],\n",
              "         [ 0,  2,  5,  1,  1,  0,  3,  8,  0,  2,  5, 15,  0, 17,  4, 15,  0,  2,\n",
              "           3,  0, 42,  4,  8,  2, 13,  4, 24, 10, 29,  5,  1,  7],\n",
              "         [ 1, 12, 10,  2,  5,  1,  1,  0,  6,  2,  7,  4,  9, 20,  5,  2, 16, 10,\n",
              "          26,  8, 12,  0, 14,  4, 28,  1,  0, 14, 15,  0, 14,  9],\n",
              "         [27,  1,  8,  0,  8,  3, 17,  0,  2,  5,  1,  0, 18,  7,  3, 57,  1,  8,\n",
              "           0, 22,  3,  6,  3, 14,  0,  3, 18,  0,  2,  5,  1,  0],\n",
              "         [ 0, 22,  7,  1,  4,  2,  5,  0,  3, 18,  0, 20,  1,  8,  2, 11,  1,  0,\n",
              "           6, 11,  1,  1, 23, 38, 10, 39,  5,  9, 19,  5,  0,  6],\n",
              "         [ 1,  0, 14, 13,  6,  2,  0, 22,  1,  0,  2,  3, 11, 12,  0,  3,  8, 30,\n",
              "           2, 16,  0,  4,  8, 12,  0,  5,  1,  0,  6,  5,  4, 11],\n",
              "         [16,  0,  3,  7,  0, 19,  5,  9, 11, 12, 25, 10, 10, 51, 32, 42, 51, 31,\n",
              "          50, 24, 10, 35,  9,  7, 16,  0,  6,  5,  1,  0, 17,  4],\n",
              "         [ 0, 13, 23,  3,  8,  0,  4,  0,  6, 13, 22,  2, 11,  1,  0, 20,  7,  3,\n",
              "          13,  8, 12, 16, 10, 21,  0,  5,  4, 27,  1,  0,  2, 13],\n",
              "         [ 4, 28,  1,  0, 22,  3, 11, 12,  0, 17,  9,  2,  5,  4, 11, 16,  0,  4,\n",
              "           8, 12,  0,  4,  6,  0, 15,  3, 13, 10,  6,  5,  4, 11],\n",
              "         [ 4, 15,  0, 15,  3, 13, 16,  0, 11,  1,  2, 30,  6,  0,  5,  1,  4,  7,\n",
              "          25, 10, 10, 51,  7,  3, 27,  3,  6,  2, 24, 10, 10, 47],\n",
              "         [ 5,  1,  7, 38, 10, 21, 30, 11, 11,  0,  5,  1,  8, 19,  1,  0,  2,  3,\n",
              "           0, 36,  3,  8, 12,  3,  8,  0,  3,  8,  0,  4,  0,  6],\n",
              "         [12, 16,  0, 19,  7, 15,  0, 30, 17,  3,  1, 46, 30,  0,  2,  5,  1,  0,\n",
              "          55, 13,  1,  1,  8, 16,  0,  2,  5,  1,  0, 55, 13,  1]]),\n",
              " tensor([[18,  3,  7,  2, 46, 10, 43, 15,  0,  4,  8, 12,  0, 22, 15, 25, 10, 21,\n",
              "           0,  5,  3, 23,  1,  0,  9,  2,  0,  9,  6,  0,  6,  3],\n",
              "         [13,  8,  2,  4,  9,  8, 16, 10, 49,  7,  3, 14,  0, 17,  5,  1,  8,  0,\n",
              "           2,  5,  9,  6,  0,  6,  2,  7,  1,  4, 14,  0,  2,  5],\n",
              "         [ 9,  6, 10, 27,  1,  7, 15,  0, 12,  4, 15,  0,  7,  1, 19,  1,  9, 27,\n",
              "           1,  6,  0, 11,  1,  2,  2,  1,  7,  6,  0,  3, 18,  0],\n",
              "         [ 0, 17,  1, 11, 11, 16,  0,  4,  8, 12,  0,  8,  3,  2,  5,  9,  8, 20,\n",
              "           0, 19,  4,  8,  0, 22,  1,  0,  9, 11, 11, 24, 10, 41],\n",
              "         [14, 23, 11,  3,  2,  2,  1, 12,  0,  4,  8, 12,  0, 19,  3,  8,  2,  7,\n",
              "           9, 27,  1, 12,  0,  9,  8,  0,  2,  5,  9,  6,  0, 11],\n",
              "         [ 2,  5,  1,  1,  0,  3,  8,  0,  2,  5, 15,  0, 17,  4, 15,  0,  2,  3,\n",
              "           0, 42,  4,  8,  2, 13,  4, 24, 10, 29,  5,  1,  7,  1],\n",
              "         [12, 10,  2,  5,  1,  1,  0,  6,  2,  7,  4,  9, 20,  5,  2, 16, 10, 26,\n",
              "           8, 12,  0, 14,  4, 28,  1,  0, 14, 15,  0, 14,  9,  6],\n",
              "         [ 1,  8,  0,  8,  3, 17,  0,  2,  5,  1,  0, 18,  7,  3, 57,  1,  8,  0,\n",
              "          22,  3,  6,  3, 14,  0,  3, 18,  0,  2,  5,  1,  0,  8],\n",
              "         [22,  7,  1,  4,  2,  5,  0,  3, 18,  0, 20,  1,  8,  2, 11,  1,  0,  6,\n",
              "          11,  1,  1, 23, 38, 10, 39,  5,  9, 19,  5,  0,  6,  3],\n",
              "         [ 0, 14, 13,  6,  2,  0, 22,  1,  0,  2,  3, 11, 12,  0,  3,  8, 30,  2,\n",
              "          16,  0,  4,  8, 12,  0,  5,  1,  0,  6,  5,  4, 11, 11],\n",
              "         [ 0,  3,  7,  0, 19,  5,  9, 11, 12, 25, 10, 10, 51, 32, 42, 51, 31, 50,\n",
              "          24, 10, 35,  9,  7, 16,  0,  6,  5,  1,  0, 17,  4,  6],\n",
              "         [13, 23,  3,  8,  0,  4,  0,  6, 13, 22,  2, 11,  1,  0, 20,  7,  3, 13,\n",
              "           8, 12, 16, 10, 21,  0,  5,  4, 27,  1,  0,  2, 13, 14],\n",
              "         [28,  1,  0, 22,  3, 11, 12,  0, 17,  9,  2,  5,  4, 11, 16,  0,  4,  8,\n",
              "          12,  0,  4,  6,  0, 15,  3, 13, 10,  6,  5,  4, 11, 11],\n",
              "         [15,  0, 15,  3, 13, 16,  0, 11,  1,  2, 30,  6,  0,  5,  1,  4,  7, 25,\n",
              "          10, 10, 51,  7,  3, 27,  3,  6,  2, 24, 10, 10, 47, 40],\n",
              "         [ 1,  7, 38, 10, 21, 30, 11, 11,  0,  5,  1,  8, 19,  1,  0,  2,  3,  0,\n",
              "          36,  3,  8, 12,  3,  8,  0,  3,  8,  0,  4,  0,  6,  1],\n",
              "         [16,  0, 19,  7, 15,  0, 30, 17,  3,  1, 46, 30,  0,  2,  5,  1,  0, 55,\n",
              "          13,  1,  1,  8, 16,  0,  2,  5,  1,  0, 55, 13,  1,  1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXD-kJsYbIA8"
      },
      "source": [
        "## 4. Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8HLT2dSMbIA8"
      },
      "outputs": [],
      "source": [
        "max_iters = 5_000      # pasos de entrenamiento\n",
        "eval_interval = 500    # cada cuántos pasos calcular (train/valid) durante el entrenamiento\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200       # tamaño de la muestra para promediar en el cálculo de la pérdida\n",
        "n_embd = 64            # tamaño de los embeddings internos\n",
        "n_head = 4             # numero de cabezas de auto-atención\n",
        "n_layer = 4            # numero de bloques Transformers\n",
        "dropout = 0.2          # aplicado después de cada autoatención, FF, y enmascarado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jBpuK1mbIA9"
      },
      "source": [
        "## 5. Módulos Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BQoV4Pa6bIA-"
      },
      "outputs": [],
      "source": [
        "class ProductoPuntoEscalado(nn.Module):\n",
        "    def __init__(self,\n",
        "                p_dropout = 0.0,\n",
        "                masc = False):\n",
        "        super(ProductoPuntoEscalado, self).__init__()\n",
        "        self.masc = masc\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        # Obtenemos dimensiones\n",
        "        m, n_cabezas, l, d_k = K.shape\n",
        "        d_v = V.shape[-1]\n",
        "\n",
        "        # Cambiamos la forma: [m, n_cabezas, l, d_k] -> [m * n_cabezas, l, d_k]\n",
        "        Q = Q.reshape(m * n_cabezas, l, d_k)\n",
        "        K = K.reshape(m * n_cabezas, l, d_k)\n",
        "        V = V.reshape(m * n_cabezas, l, d_v)\n",
        "\n",
        "        # Q y K tienen forma [m * n_cabezas, l, d_k],\n",
        "        # por lo que se transponen las dos últimas dimensiones de K\n",
        "        # QK: [m * n_cabezas, l, l]\n",
        "        QK = th.bmm(Q, K.transpose(1, 2))\n",
        "\n",
        "        # se escalan los valores QK\n",
        "        QK_esc = QK / th.math.sqrt(d_k)\n",
        "\n",
        "        if self.masc:\n",
        "            # Creamos una matriz triangular superior binaria (excluyendo la diagonal)\n",
        "            masc = th.triu(th.ones((l, l), dtype = th.bool, device = Q.device),\n",
        "                          diagonal = 1)\n",
        "            # Ponemos los valores de QK_esc en los que la máscara sea 1 a -inf\n",
        "            QK_esc = QK_esc.masked_fill_(masc, -th.inf)\n",
        "\n",
        "        # mapas de atención: [m * n_cabezas, l, l] -> [m * n_cabezas, l, l]\n",
        "        alfas = nn.functional.softmax(QK_esc, dim=-1)\n",
        "        alfas = self.dropout(alfas) # Se agrega dropout de acuerdo al codigo de nanoGPT\n",
        "\n",
        "        # vectores de salida y\n",
        "        # alfas: [m * n_cabezas, l, l], V: [m * n_cabezas, l, d_v]\n",
        "        # Y: [m * n_cabezas, l, d_v]\n",
        "        Y = th.bmm(alfas, V)\n",
        "\n",
        "        # Cambiamos la forma: [m * n_cabezas, l, d_v] -> [m, n_cabezas, l, d_v]\n",
        "        Y = Y.reshape(m, n_cabezas, l, d_v)\n",
        "\n",
        "        # Cambiamos la forma: [m * n_cabezas, l, l] -> [m, n_cabezas, l, l]\n",
        "        alfas = alfas.reshape(m, n_cabezas, l, l)\n",
        "\n",
        "        return Y, alfas\n",
        "\n",
        "\n",
        "class AtencionMulticabeza(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_modelo,\n",
        "                n_cabezas,\n",
        "                p_dropout = 0.0,\n",
        "                masc = False):\n",
        "        super(AtencionMulticabeza, self).__init__()\n",
        "\n",
        "        self.n_cabezas = n_cabezas\n",
        "        self.d_modelo = d_modelo\n",
        "\n",
        "        self.d_cabezas = self.d_modelo // self.n_cabezas\n",
        "\n",
        "        self.ppe = ProductoPuntoEscalado(p_dropout=p_dropout, masc = masc)\n",
        "        self.proy_Q = nn.Linear(self.d_modelo, self.d_modelo, bias = False)\n",
        "        self.proy_K = nn.Linear(self.d_modelo, self.d_modelo, bias = False)\n",
        "        self.proy_V = nn.Linear(self.d_modelo, self.d_modelo, bias = False)\n",
        "        self.proy_sal = nn.Linear(self.d_modelo, self.d_modelo)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m, l, d_modelo = x.shape\n",
        "\n",
        "        # Cambiamos la forma del tensor x\n",
        "        # [m, l, d_modelo] -> [m * l, d_modelo]\n",
        "        x = x.reshape(m * l, d_modelo)\n",
        "\n",
        "        # Proyectamos vectores en x a Q, K, V\n",
        "        # [m * l, d_modelo] -> [m * l, d_modelo]\n",
        "        Q = self.proy_Q(x)\n",
        "        K = self.proy_K(x)\n",
        "        V = self.proy_V(x)\n",
        "\n",
        "        # Cambiamos la forma: [m * l, d_modelo] -> [m, l, n_cabezas, d_k]\n",
        "        # d_k = d_v = self.d_modelo // self.n_cabezas\n",
        "        Q = Q.reshape(m, l, self.n_cabezas, self.d_cabezas)\n",
        "        K = K.reshape(m, l, self.n_cabezas, self.d_cabezas)\n",
        "        V = V.reshape(m, l, self.n_cabezas, self.d_cabezas)\n",
        "\n",
        "        # Transponemos el eje de las cabezas a la segunda posición del tensor y\n",
        "        # creamos copia (con .contiguous()) para que esté almacenado en memoria de\n",
        "        # forma contigua (.transpose() hace que ya no sea así).\n",
        "        # [m, l, n_cabezas, d_k] -> [m, n_cabezas, l, d_k]\n",
        "        Q = Q.transpose(1, 2).contiguous()\n",
        "        K = K.transpose(1, 2).contiguous()\n",
        "        V = V.transpose(1, 2).contiguous()\n",
        "\n",
        "        # Calculamos el producto punto escalado con Q, K y V\n",
        "        # Q, K: [m, n_cabezas, l, d_k], V:[m, n_cabezas, l, d_v]\n",
        "        # Y: [m, n_cabezas, l, d_v], alfas: [m, n_cabezas, l, l]\n",
        "        Y, alfas = self.ppe(Q, K, V)\n",
        "\n",
        "        # Transponermos el eje de cabezas a la penúltima posición:\n",
        "        # [m, n_cabezas, l, d_k] -> [m, l, n_cabezas, d_k]\n",
        "        Y = Y.transpose(1, 2).contiguous()\n",
        "\n",
        "        # Concatemanos los vectores de todas las cabezas en un solo vector\n",
        "        # [m, l, n_cabezas, d_k] -> [m * l, d_modelo]\n",
        "        # d_modelo = n_cabezas * d_k\n",
        "        Y = Y.reshape(m * l, self.d_modelo)\n",
        "\n",
        "        # Proyectamos la vectores concatenados para obtener la salida\n",
        "        # [m * l, d_modelo] -> [m * l, d_modelo]\n",
        "        Y = self.proy_sal(Y)\n",
        "\n",
        "        # Concatemanos los vectores de todas las cabezas en un solo vector\n",
        "        # [m * l, d_modelo] -> [m, l, d_modelo]\n",
        "        Y = Y.reshape(m, l, self.d_modelo)\n",
        "\n",
        "        return Y, alfas\n",
        "\n",
        "class RedDensaPosicion(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_modelo,\n",
        "                d_ff):\n",
        "        super(RedDensaPosicion, self).__init__()\n",
        "        self.d_modelo = d_modelo\n",
        "        self.d_ff = self.d_ff = d_ff if d_ff else 4*d_modelo\n",
        "        self.densa1 = nn.Linear(self.d_modelo, self.d_ff)\n",
        "        self.densa2 = nn.Linear(self.d_ff, self.d_modelo)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m, l, d_modelo = x.shape\n",
        "\n",
        "        # Cambiamos la forma: [m, l, d_modelo] -> [m * l, d_modelo]\n",
        "        x = x.reshape(m * l, d_modelo)\n",
        "\n",
        "        # Pasamos el tensor redimensionado por la red densa\n",
        "        # [m * l, d_modelo] -> [m * l, d_modelo]\n",
        "        x = self.densa1(x)\n",
        "        x = nn.functional.gelu(x)\n",
        "        x = self.densa2(x)\n",
        "\n",
        "        # Lo regresamos a su forma original\n",
        "        # [m * l, d_modelo] -> [m, l, d_modelo]\n",
        "        x = x.reshape(m, l, d_modelo)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class BloqueTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_modelo,\n",
        "                n_cabezas,\n",
        "                d_rdp=None,\n",
        "                p_dropout = 0.1,\n",
        "                masc = False):\n",
        "        super(BloqueTransformer, self).__init__()\n",
        "        self.amc = AtencionMulticabeza(d_modelo = d_modelo,\n",
        "                                      n_cabezas = n_cabezas,\n",
        "                                      p_dropout = p_dropout,\n",
        "                                      masc = masc)\n",
        "        self.norm1 = nn.LayerNorm(d_modelo)\n",
        "        self.rp = RedDensaPosicion(d_modelo, d_rdp)\n",
        "        self.norm2 = nn.LayerNorm(d_modelo)\n",
        "        self.dropout1 = nn.Dropout(p_dropout)\n",
        "        self.dropout2 = nn.Dropout(p_dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        salidas_amc, alfas = self.amc(x)\n",
        "        salidas_amc = self.dropout1(salidas_amc)\n",
        "        salidas_amc = self.norm1(x + salidas_amc)\n",
        "\n",
        "        salidas_rp = self.rp(salidas_amc)\n",
        "        salidas_rp = self.dropout2(salidas_rp)\n",
        "\n",
        "        return self.norm2(salidas_amc + salidas_rp)\n",
        "\n",
        "\n",
        "class CodificacionPosicional(nn.Module):\n",
        "    def __init__(self,\n",
        "                maxsec,\n",
        "                d_modelo,\n",
        "                p_dropout = 0.1):\n",
        "        super(CodificacionPosicional, self).__init__()\n",
        "\n",
        "        self.maxsec = maxsec\n",
        "        self.d_modelo = d_modelo\n",
        "\n",
        "        cod_pos = th.zeros((self.maxsec, self.d_modelo))\n",
        "\n",
        "        # Creamos tensor con valores pares 0, 2, 4, ...\n",
        "        # i: [d_modelo // 2, 1]\n",
        "        i = th.arange(0, self.d_modelo, 2, dtype=th.float).reshape(-1, 1)\n",
        "\n",
        "        # Creamos tensor de posiciones 0, 1, ...\n",
        "        # pos: [maxsec, 1]\n",
        "        pos = th.arange(0, self.maxsec, dtype=th.float).reshape(-1, 1)\n",
        "        a = 1.0 / 10000**(i / self.d_modelo)\n",
        "\n",
        "        # grados: [maxsec, d_modelo // 2]\n",
        "        grados = pos @ a.T\n",
        "\n",
        "        cod_pos[:, 0::2] = th.sin(grados) # Para pares\n",
        "        cod_pos[:, 1::2] = th.cos(grados) # Para impares\n",
        "\n",
        "        # Registramos tensor de codificación posicional\n",
        "        self.register_buffer('cod_pos', cod_pos)\n",
        "\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m, l, d_modelo = x.shape\n",
        "        return x + self.cod_pos[:l, :]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiTLidp2bIA_"
      },
      "source": [
        "## 6. Modelo GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q4HBDnWxbIA_"
      },
      "outputs": [],
      "source": [
        "class nanoGPT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # lookup table para obtener vectores densos para cada token de la oracion\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        # obtener y sumar el embedding posicional\n",
        "        self.position_embedding = CodificacionPosicional(context_size, n_embd)\n",
        "        # agregar n_layer bloques transformer enmascarados, con n_cabezas cada uno\n",
        "        self.blocks = nn.Sequential(*[BloqueTransformer(n_embd, n_cabezas=n_head, p_dropout=dropout, masc=True) for _ in range(n_layer)])\n",
        "        # al final de todos los bloques transformers se agrega una capa de normalizacion\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        # capa densa para mapear de dimension n_embd a todo el vocabulario\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # B -> Batch (M)\n",
        "        # T -> Time (L)\n",
        "        # C -> Channels (D)\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx y targets son ambos tensores de enteros de dimension (B,T)\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = self.position_embedding(tok_emb) # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        # cuando se genera texto, no hay targets y no hay perdida\n",
        "        # cuando se entrena, hay targets y se calcula perdida\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            # se adaptan logits y targets pues F.cross_entropy espera un tensor 2D\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx es un arreglo de indices de dimensiones (B, T)\n",
        "        for _ in range(max_new_tokens):\n",
        "            # recortar idx para tomar como contexto solo tokens hasta context_size\n",
        "            idx_cond = idx[:, -context_size:]\n",
        "            # obtener predicciones, la perdida es ignorada\n",
        "            logits, loss = self(idx_cond)\n",
        "            # tomar el logit del ultimo token\n",
        "            logits = logits[:, -1, :] # (B, T, C) -> (B, C)\n",
        "            # obtener las probabilidades de la siguiente palabra\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # muestrear la predicción a partir de la distribucion dada por softmax\n",
        "            idx_next = th.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # agregar prediccion al final de idx\n",
        "            idx = th.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Durante el entrenamiento, cada (eval_interval) pasos, se obtienen\n",
        "# (eval_iters) perdidas y se promedian para monitorear el estado del\n",
        "# entrenamiento\n",
        "\n",
        "@th.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = th.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "uX7Zx6Kfda62"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LraIAVtgbIA_"
      },
      "source": [
        "## 7. Instanciar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veiYc5BabIA_",
        "outputId": "a06507d6-c60d-4d1e-94df-ca830ee7e03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.207681 M parameters\n"
          ]
        }
      ],
      "source": [
        "model = nanoGPT()\n",
        "m = model.to(device)\n",
        "\n",
        "# imprime el número de parámetros en el modelo\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BHq74gCbIA_"
      },
      "source": [
        "### 7.1 Ejemplo de generación sin entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zylxj1LIbIBA",
        "outputId": "bcdace15-8b5b-4d57-bae3-aeb750a61bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I3YXinX&TXb??QTqwf,uimqYmSCZtvNBxxMpLP&AO!Nhs\n",
            "\n",
            "zKudJu!PHYz&zx$Q3&chuoD-!KW.$wGghrB'AYECBzI:IxgKVYZ&P!igSMKixQCMStRhaI.UHV&NRIoX'jaM.pYKRNR&dYKY&EniuFZwX.U;T3FXesjtifinQBuKd'$ufTuuBEjMK!$, LAmGKU!RFIDseIrReCTM.WBY!-UKWgh,QTZ?nxhMWfMC?CtSYH'HIskDFs .'nSZMmF.mtVc-v'BxAgSI&zxqR&hhC,KSxTlPjIKTIe$'dSrzdzhSEwaqBtKKZQz'$xhILh-mzJhM;Y?msU&,,XRg.D-3FIEwQ:  -\n",
            "lUpChw&,a$!XCqXh'ahMY'c&tc.&TuF3BVp:xmr!QjIulnpGkdfx b3rEu?vc&ztDBaZZMB?tJqKQT3LhzsI,.QpOxnCq-HpWaPM$TKSNuzZ'r:ApD;-dRRau-DzC-tTSY?XudZKQ3'A&AmaZnWEV3CuRq-HDa&pROPptXJjhKKzrpsD&zDM&RG\n",
            "qNhJARYrdrMqPHA\n",
            "S,bq.-P?\n",
            "3R-FwQ'Pf$CfZjuMkmuc,$LC3xENVamfOOQN,BJjz;EVcPAKiZdW.USIVIS,ZVdqdaJHusM\n",
            ";sgPUscIZdSuIuNRsEX:?I -\n",
            ",SEF?GVc'?zELKNL.lIluSrksI&KuySSY$,R-aQIWMSVm3M.ztg.Cw'DY,SKqtSoLzzPPdRIhi.'A.WuILYzCf!uFgujZ!oJXYOz\n",
            "LCXzjV'wtTVZMTpzwbKMP??;mIP'AEVHYn!I;?YHP?p\n",
            "R:n&3hwaT?vzb-hCZKOhQ?sPmPNuaQx-aqFH\n",
            "G &TGJIw$!u-aaQPNdEYjw;Z3Q3;BXQpem,$vVQVsOVydHiXdj&QU$W-I;$T?zCh!Q$mGrt Ep.qRiDmwphbSWQj-maQr;ueS!hxI HmFIDh&QZ;KUstEfdMqdxPRPo?spvMJ&'3n$maiHgixsIKftrpDpA-H\n",
            "HSs KT';Xu$h'BujhwVpzKhafY-;$Y'GjMSIcmbDuxjUK;$quox$DE,fXS A&'CMDS fpf-V!CPSdQgX p'E$VZIQ&oY.!VC-Dho3$qOYSpSQzxOkU;t\n",
            "XZWWw-zDuVKWQ3TDIxIlzGX ,HgrFhbW?zulKiPPJt&P;GxS,JTtoRuI 3,-QCh.SYiFLzKGwk&o?K3;JFWSuLKSOVhH$bXdhE!-$ xOIhAgg&ctlFXxZiBuAA\n",
            "nBjn,3C-dnm3HZ:C'UHb IujK?gtSzbyBhGQDI-zMhQUNIIYrbmxjIOUSwvVps;GB;dnaPKWCfuuwQzaWalGJ'C$ .$,cIllRIH D,H hab3-.''KwCTrRIz3;hW,wTWcfPbp&,y,PSasCCZp.yMGSVchPe'SSuiAaErxuJyV!Erlm3S!CuSuFC.rV 'oPIsYQ3h--ZssUjQzp&V&pa ;TQCsvYWXCKQ.tJEuxMsUC\n",
            "bNX!nONLjS3ehuH;wdq$Ua'- CCNjuKDIH;Rha&ILM.xwGwBgxQooS$ PCDD,Pzr$i$V'QUgD;a&nGBWM?DDgMrHp&-&Bts EtV&j H;VcCZiX3ScQ-I..tSSfJ'-;,Q;kDibUtSW;lxeKODSE'Ca!rzrRyjNmRnCaO&mPlW pJdfTQul\n",
            ",$u$!KwbD.wD'KDwAK,;uyx;sTFBR'ooSSiskWe;IhcUPY\n",
            "kzDICCx&zKSJhChuoRHq!$Jd'jMhFw!ttH!YMDSc!wR'QanMaHnHInpiXK'I$JEZKTuSP:DKTVG.glf$I:o\n",
            "&qyvmX-OhSWjIZY.aQuA,CXgSAnQH3PkIznpvxZiIMpeXPk-'vnnojm;!Jm&STHYhIyILu,'IkvR3Chjv XQkdTrn,zDE;Ju?Qp&PwPAmukgDZZhY;Tk'imm,utPQP\n",
            "eIuSx.ru$l'PRBZWK;fpuB$L$H$VunaFIKK3s!rWI3BV&-C'QBhaGy.s.ksdf-tKPVApYqKXYfxIyE!SI$XIqE.W:yrp\n"
          ]
        }
      ],
      "source": [
        "# generar del modelo a partir de una entrada [0]\n",
        "context = th.zeros((1, 1), dtype=th.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgV9XqGObIBA"
      },
      "source": [
        "## 8. Entrenar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lkPlEY4bIBA",
        "outputId": "18b82f9f-a72a-4e02-835b-e8566b945f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.3974, val loss 4.3949\n",
            "step 500: train loss 2.2592, val loss 2.2736\n",
            "step 1000: train loss 2.0711, val loss 2.1104\n",
            "step 1500: train loss 1.9818, val loss 2.0558\n",
            "step 2000: train loss 1.9121, val loss 2.0108\n",
            "step 2500: train loss 1.8592, val loss 1.9667\n",
            "step 3000: train loss 1.8175, val loss 1.9271\n",
            "step 3500: train loss 1.7952, val loss 1.9195\n",
            "step 4000: train loss 1.7699, val loss 1.9047\n",
            "step 4500: train loss 1.7358, val loss 1.8913\n",
            "step 4999: train loss 1.7286, val loss 1.8842\n"
          ]
        }
      ],
      "source": [
        "# crear optimizador\n",
        "optimizer = th.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # calcular la perdida cada eval_interval\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # generar lote\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # paso\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXAqZ1DUbIBA"
      },
      "source": [
        "### 8.1 Ejemplo de generación con modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEaAdCKKbIBA",
        "outputId": "08267b2e-e7a2-40c9-8d02-6dffae294a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " in she re o'e gues that like\n",
            "Haves likestion, buld to my will to naess,\n",
            "Who, thou arms! Souccious thy be\n",
            "doneinthey nigh strust mint, his asfs he rof or your eglight.\n",
            "\n",
            "LUCENTIO:\n",
            "Doldy you thellent shut\n",
            "trould in the loftymes so dones;\n",
            "And I lie I from leaty it boooil disue\n",
            "Of cuar; sleess wear that pacrerge.\n",
            "\n",
            "BOfirt your althiced I which a dother's put be yours\n",
            "Is thought thank consel banigin a ptace;\n",
            "To the reeepect are our osesdon thow lim.\n",
            "\n",
            "MOLUMPEROVERGO:\n",
            "How is men, to'telle brosand onset to our butder'd.\n",
            "\n",
            "MENENIUS:\n",
            "Con PoGin nut king my foulse, make ary,\n",
            "Hisse, as lechembind, aind,\n",
            "Yonowe: and we mere in twees gongue,\n",
            "We posting'd such the toursuand a Qudes the his prose,\n",
            "Comblese thous withen an knemlings.\n",
            "\n",
            "\n",
            "ETEEER:\n",
            "I her the whatish willle blookse, my nothing.\n",
            "\n",
            "ELAREANUMENENIUS:\n",
            "I blick? of our thuld enourgue,\n",
            "Tembinage hast your hat chetive;\n",
            "Yoncly at your oFf Yelles; I love liver-up and yom lory bring, have in so had\n",
            "Conpoin Larews, not fares world ane the houind.\n",
            " st noble and hust and what apparce prict fat,\n",
            "And lilime, me with and dour ded, wee harser Ofilit comfe,\n",
            "not couly's it ie! you, I spell\n",
            "minoth ploon condrienest to\n",
            "What are for be misend ain: you speas doyer clenes wor\n",
            "Anter sevings my of of the bronglise.\n",
            "Than porting you nor may fait too night.\n",
            "\n",
            "\n",
            "ROMEO:\n",
            "Stninge to weace suwn the lords merby to my the glavises of will thy where igness\n",
            "As.\n",
            "Night? all I king As craite\n",
            "Of than a banida.\n",
            "\n",
            "ESVIRENCE:\n",
            "HENRY noves prutt youne do. Buticklem, but I thou ofkes, the than ofe lot meere digpin loves,\n",
            "Whated an aret mouckes, by hers deshipt thesel-dune one;\n",
            "And at not one.\n",
            "I bear the hath lifief, but souin he brove egrleeed\n",
            "Aond hat a from to blow's thilde you a neswell\n",
            "Asough pleaq's liace move!\n",
            "in is full bed, seemple one:\n",
            "Rome harew.\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "Macked hysell, swanborived wills;\n",
            "And though Clove proved yeares of so lunguban of hith sencure Raporcildy' dipend an foour happpater's but en:\n",
            "I ne, tone leadong wiparce bosongy\n",
            "an a shat vead nothips has gaat\n"
          ]
        }
      ],
      "source": [
        "# generar del modelo a partir de una entrada [0]\n",
        "context = th.zeros((1, 1), dtype=th.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7d6qJ43s5O0o"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}